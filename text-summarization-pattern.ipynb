{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Text With boto3\n",
    "\n",
    "First we will summarize a short text, lets create a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Human: Please provide a summary of the following text.\n",
    "<text>\n",
    "AWS took all of that feedback from customers, and today we are excited to announce Amazon Bedrock, \\\n",
    "a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. \\\n",
    "Bedrock is the easiest way for customers to build and scale generative AI-based applications using FMs, \\\n",
    "democratizing access for all builders. Bedrock will offer the ability to access a range of powerful FMs \\\n",
    "for text and images—including Amazons Titan FMs, which consist of two new LLMs we’re also announcing \\\n",
    "today—through a scalable, reliable, and secure AWS managed service. With Bedrock’s serverless experience, \\\n",
    "customers can easily find the right model for what they’re trying to get done, get started quickly, privately \\\n",
    "customize FMs with their own data, and easily integrate and deploy them into their applications using the AWS \\\n",
    "tools and capabilities they are familiar with, without having to manage any infrastructure (including integrations \\\n",
    "with Amazon SageMaker ML features like Experiments to test different models and Pipelines to manage their FMs at scale).\n",
    "</text>\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the body for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"prompt\": prompt,\n",
    "                 \"max_tokens_to_sample\":4096,\n",
    "                 \"temperature\":0.5,\n",
    "                 \"top_k\":250,\n",
    "                 \"top_p\":0.5,\n",
    "                 \"stop_sequences\":[]\n",
    "                  }) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the key points from the text:\n",
      "\n",
      "- AWS announced Amazon Bedrock, a new service that provides API access to large language models (LLMs) from AI21 Labs, Anthropic, Stability AI, and Amazon. \n",
      "\n",
      "- Bedrock aims to make generative AI more accessible to developers by allowing them to easily integrate and deploy powerful text and image generation models into their applications.\n",
      "\n",
      "- Bedrock offers serverless access to models including two new Titan LLMs from Amazon. \n",
      "\n",
      "- Key benefits of Bedrock include scalability, reliability, security, easy integration with AWS services, and the ability to customize models with your own data without managing infrastructure.\n"
     ]
    }
   ],
   "source": [
    "modelId = 'anthropic.claude-v2' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "print(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk': {'bytes': b'{\"completion\":\" Here\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" is\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" a\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" summary\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" of\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" the\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" key\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" points\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" from\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" the\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" text\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\":\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"\\\\n\\\\n-\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" AWS\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" announced\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Amazon\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Bed\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"rock\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" a\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" new\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" service\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" that\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" provides\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" API\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" access\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" large\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" language\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" models\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" (\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"LL\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"Ms\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\")\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" from\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" AI\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"21\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Labs\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" An\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"throp\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"ic\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" St\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"ability\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" AI\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" and\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Amazon\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\".\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" \",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"\\\\n\\\\n-\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Bed\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"rock\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" aims\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" make\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" gener\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"ative\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" AI\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" more\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" accessible\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" developers\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" by\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" allowing\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" them\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" easily\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" integrate\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" and\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" deploy\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" powerful\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" text\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" and\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" image\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" generation\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" models\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" into\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" their\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" applications\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\".\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"\\\\n\\\\n-\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Bed\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"rock\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" offers\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" server\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"less\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" access\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" models\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" including\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" two\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" new\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Titan\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" LL\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"Ms\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" from\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Amazon\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\".\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" \",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"\\\\n\\\\n-\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Key\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" benefits\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" of\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Bed\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"rock\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" include\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" scal\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"ability\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" reliability\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" security\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" easy\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" integration\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" with\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" AWS\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" services\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" and\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" the\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" ability\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" customize\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" models\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" with\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" your\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" own\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" data\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" without\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" managing\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" infrastructure\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\".\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"\",\"stop_reason\":\"stop_sequence\",\"stop\":\"\\\\n\\\\nHuman:\",\"amazon-bedrock-invocationMetrics\":{\"inputTokenCount\":249,\"outputTokenCount\":145,\"invocationLatency\":4397,\"firstByteLatency\":579}}'}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelId = 'anthropic.claude-v2'\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = list(stream)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the output in a more cosumable manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown,Markdown,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Here is a summary of the key points from the text:\n",
       "\n",
       "- AWS announced Amazon Bedrock, a new service that provides API access to large language models (LLMs) from AI21 Labs, Anthropic, Stability AI, and Amazon. \n",
       "\n",
       "- Bedrock aims to make generative AI more accessible to developers by allowing them to easily integrate and deploy powerful text and image generation models into their applications.\n",
       "\n",
       "- Bedrock offers serverless access to models including two new Titan LLMs from Amazon. \n",
       "\n",
       "- Key benefits of Bedrock include scalability, reliability, security, easy integration with AWS services, and the ability to customize models with your own data without managing infrastructure."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelId = 'anthropic.claude-v2'\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = []\n",
    "i = 1\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "            text = chunk_obj['completion']\n",
    "            clear_output(wait=True)\n",
    "            output.append(text)\n",
    "            display_markdown(Markdown(''.join(output)))\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same example using Claude3 Sonnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt}]}]\n",
    "\n",
    "body=json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 512,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0.5,\n",
    "            \"top_p\": 1\n",
    "        }  \n",
    "    )  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the provided text:\n",
      "\n",
      "AWS has announced a new service called Amazon Bedrock that provides access to foundation models (FMs) from AI companies like AI21 Labs, Anthropic, Stability AI, and Amazon itself via an API. Bedrock aims to democratize access to powerful generative AI models for text and images, including Amazon's own new Titan large language models announced today.\n",
      "\n",
      "Bedrock offers a serverless experience, allowing customers to easily find and use the right FM for their needs, customize models with their own data, and integrate them into applications using familiar AWS tools and services. This eliminates the need to manage infrastructure.\n",
      "\n",
      "Key features of Bedrock include the ability to access a range of FMs, privately customize models, easily integrate them into applications, and leverage AWS capabilities like SageMaker Experiments to test models and SageMaker Pipelines to manage models at scale. Overall, Bedrock is designed to simplify building and scaling generative AI applications using foundation models.\n"
     ]
    }
   ],
   "source": [
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "response = bedrock_client.invoke_model(body=body, modelId=modelId)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "#print(response_body)\n",
    "output_list = response_body.get(\"content\", [])\n",
    "for output in output_list:\n",
    "    print(output[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk': {'bytes': b'{\"type\":\"message_start\",\"message\":{\"id\":\"msg_01QJrGJyZTZBgN2aFrDGkKQ1\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[],\"model\":\"claude-3-sonnet-28k-20240229\",\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":263,\"output_tokens\":1}}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_start\",\"index\":0,\"content_block\":{\"type\":\"text\",\"text\":\"\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"Here\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" is\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" a\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" summary\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" of\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" the\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" provided\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" text\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\":\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"\\\\n\\\\nAWS\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" has\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" announced\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" a\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" new\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" service\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" called\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Amazon\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Bed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"rock\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" that\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" provides\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" access\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" foundation\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" (\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"F\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"Ms\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\")\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" from\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AI\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" companies\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" like\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AI\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"21\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" \"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"Labs\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Anthrop\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ic\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Stability\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AI\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Amazon\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" itself\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" via\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" an\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" API\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Bed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"rock\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" aims\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" democrat\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ize\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" access\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" powerful\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" gener\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ative\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AI\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" for\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" text\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" images\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" including\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Amazon\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"\\'s\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" own\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" new\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Titan\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" large\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" language\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" \"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"\\\\n\\\\nBed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"rock\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" offers\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" a\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" server\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"less\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" experience\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" that\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" allows\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" customers\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" easily\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" find\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" the\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" right\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" model\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" for\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" their\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" needs\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" get\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" started\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" quickly\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" customize\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" with\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" their\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" own\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" data\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" integrate\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" the\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" into\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" their\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" applications\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" using\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" familiar\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AWS\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" tools\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" services\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" This\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" elimin\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ates\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" the\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" need\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" manage\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" infrastructure\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"\\\\n\\\\nKey\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" features\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" of\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Bed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"rock\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" include\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" the\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" ability\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" access\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" a\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" range\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" of\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" F\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"Ms\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" privately\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" customize\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" easily\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" integrate\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" them\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" into\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" applications\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" leverage\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AWS\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" capabilities\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" like\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" S\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ag\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"eM\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"aker\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Experiments\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" test\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" S\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ag\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"eM\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"aker\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Pip\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"elines\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" manage\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" at\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" scale\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Overall\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Bed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"rock\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" is\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" designed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" make\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" it\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" easier\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" for\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" all\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" builders\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" develop\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" scale\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" gener\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ative\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AI\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" applications\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_stop\",\"index\":0}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"message_delta\",\"delta\":{\"stop_reason\":\"end_turn\",\"stop_sequence\":null},\"usage\":{\"output_tokens\":224}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"message_stop\",\"amazon-bedrock-invocationMetrics\":{\"inputTokenCount\":263,\"outputTokenCount\":224,\"invocationLatency\":4807,\"firstByteLatency\":526}}'}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\", accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = list(stream)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the provided text:\n",
      "\n",
      "AWS has announced a new service called Amazon Bedrock that provides access to foundation models (FMs) from AI companies like AI21 Labs, Anthropic, Stability AI, and Amazon itself via an API. Bedrock aims to make it easier for customers to build and scale generative AI applications using these powerful language models.\n",
      "\n",
      "Key points:\n",
      "\n",
      "- Bedrock offers access to a range of FMs for text and images through a scalable, secure AWS managed service.\n",
      "- It includes Amazon's new Titan FMs, which are two new large language models announced today.\n",
      "- Customers can easily find the right model, get started quickly, privately customize models with their own data, and integrate them into applications using familiar AWS tools.\n",
      "- Bedrock provides a serverless experience without having to manage infrastructure.\n",
      "- It integrates with Amazon SageMaker features like Experiments and Pipelines to test different models and manage them at scale.\n",
      "- The goal is to democratize access to generative AI models for all builders.\n",
      "Stop reason: end_turn\n",
      "Stop sequence: None\n",
      "Output tokens: 231\n"
     ]
    }
   ],
   "source": [
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\", accept=accept, contentType=contentType)\n",
    "for event in response.get(\"body\"):\n",
    "    chunk = json.loads(event[\"chunk\"][\"bytes\"])\n",
    "\n",
    "    if chunk['type'] == 'message_delta':\n",
    "        print(f\"\\nStop reason: {chunk['delta']['stop_reason']}\")\n",
    "        print(f\"Stop sequence: {chunk['delta']['stop_sequence']}\")\n",
    "        print(f\"Output tokens: {chunk['usage']['output_tokens']}\")\n",
    "\n",
    "    if chunk['type'] == 'content_block_delta':\n",
    "        if chunk['delta']['type'] == 'text_delta':\n",
    "            print(chunk['delta']['text'], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing a Long Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying an LLM for LangChain Bedrock class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockLLM\n",
    "modelId = \"amazon.titan-tg1-large\"\n",
    "llm = BedrockLLM(\n",
    "    model_id=modelId,\n",
    "    model_kwargs={\n",
    "        \"maxTokenCount\": 4096,\n",
    "        \"stopSequences\": [],\n",
    "        \"temperature\": 0,\n",
    "        \"topP\": 1,\n",
    "    },\n",
    "    client=bedrock_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading text File with many Tokens\n",
    "\n",
    "We will load the text file located in ./letters/2022-letter.txt and count the number of tokens in the file.\n",
    "The text, too long to fit in the prompt, will be spited into smaller chunks with RecursiveCharacterTextSplitter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 10 documents and the first one has 439 tokens\n"
     ]
    }
   ],
   "source": [
    "#%pip install transformers\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\"], chunk_size=4000, chunk_overlap=100\n",
    ")\n",
    "\n",
    "docs = text_splitter.create_documents([letter])\n",
    "\n",
    "num_docs = len(docs)\n",
    "\n",
    "num_tokens_first_doc = llm.get_num_tokens(docs[0].page_content)\n",
    "\n",
    "print(\n",
    "    f\"Now we have {num_docs} documents and the first one has {num_tokens_first_doc} tokens\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the chunks\n",
    "To summarize the chunks we can use three ways: \n",
    "\n",
    "- `stuff` puts all the chunks into one prompt. Thus, this would hit the maximum limit of tokens.\n",
    "- `map_reduce`(calls the LLM multiple times) summarizes eacth chunk, combines the summary, and summarizes the combined summary. If the combined summary is too large, it would raise error. \n",
    "- `refine` (calls the LLM multiple times) summarizes chunks in sequence consolidating. \n",
    "\n",
    "Let´s try `map_reduce`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "summary_chain = load_summarize_chain(llm=llm, chain_type=\"map_reduce\", verbose=False)\n",
    "\n",
    "output = \"\"\n",
    "try:\n",
    "    \n",
    "    output = summary_chain.invoke(docs)\n",
    "\n",
    "except ValueError as error:\n",
    "    if  \"AccessDeniedException\" in str(error):\n",
    "        print(f\"\\x1b[41m{error}\\\n",
    "        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_documents': [Document(page_content='As I sit down to write my second annual shareholder letter as CEO, I find myself optimistic and energized by what lies ahead for Amazon. Despite 2022 being one of the harder macroeconomic years in recent memory, and with some of our own operating challenges to boot, we still found a way to grow demand (on top of the unprecedented growth we experienced in the first half of the pandemic). We innovated in our largest businesses to meaningfully improve customer experience short and long term. And, we made important adjustments in our investment decisions and the way in which we’ll invent moving forward, while still preserving the long-term investments that we believe can change the future of Amazon for customers, shareholders, and employees.\\n\\nWhile there were an unusual number of simultaneous challenges this past year, the reality is that if you operate in large, dynamic, global market segments with many capable and well-funded competitors (the conditions in which Amazon operates all of its businesses), conditions rarely stay stagnant for long.\\n\\nIn the 25 years I’ve been at Amazon, there has been constant change, much of which we’ve initiated ourselves. When I joined Amazon in 1997, we had booked $15M in revenue in 1996, were a books-only retailer, did not have a third-party marketplace, and only shipped to addresses in the US. Today, Amazon sells nearly every physical and digital retail item you can imagine, with a vibrant third-party seller ecosystem that accounts for 60% of our unit sales, and reaches customers in virtually every country around the world. Similarly, building a business around a set of technology infrastructure services in the cloud was not obvious in 2003 when we started pursuing AWS, and still wasn’t when we launched our first services in 2006. Having virtually every book at your fingertips in 60 seconds, and then being able to store and retrieve them on a lightweight digital reader was not “a thing” yet when we launched Kindle in 2007, nor was a voice-driven personal assistant like Alexa (launched in 2014) that you could use to access entertainment, control your smart home, shop, and retrieve all sorts of information.'), Document(page_content='There have also been times when macroeconomic conditions or operating inefficiencies have presented us with new challenges. For instance, in the 2001 dot-com crash, we had to secure letters of credit to buy inventory for the holidays, streamline costs to deliver better profitability for the business, yet still prioritized the long-term customer experience and business we were trying to build (if you remember, we actually lowered prices in most of our categories during that tenuous 2001 period). You saw this sort of balancing again in 2008-2009 as we endured the recession provoked by the mortgage-backed securities financial crisis. We took several actions to manage the cost structure and efficiency of our Stores business, but we also balanced this streamlining with investment in customer experiences that we believed could be substantial future businesses with strong returns for shareholders. In 2008, AWS was still a fairly small, fledgling business. We knew we were on to something, but it still required substantial capital investment. There were voices inside and outside of the company questioning why Amazon (known mostly as an online retailer then) would be investing so much in cloud computing. But, we knew we were inventing something special that could create a lot of value for customers and Amazon in the future. We had a head start on potential competitors; and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision to continue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, with strong profitability, that has transformed how customers from start-ups to multinational companies to public sector organizations manage their technology infrastructure. Amazon would be a different company if we’d slowed investment in AWS during that 2008-2009 period.\\n\\nChange is always around the corner. Sometimes, you proactively invite it in, and sometimes it just comes a-knocking. But, when you see it’s coming, you have to embrace it. And, the companies that do this well over a long period of time usually succeed. I’m optimistic about our future prospects because I like the way our team is responding to the changes we see in front of us.\\n\\nOver the last several months, we took a deep look across the company, business by business, invention by invention, and asked ourselves whether we had conviction about each initiative’s long-term potential to drive enough revenue, operating income, free cash flow, and return on invested capital. In some cases, it led to us shuttering certain businesses. For instance, we stopped pursuing physical store concepts like our Bookstores and 4 Star stores, closed our Amazon Fabric and Amazon Care efforts, and moved on from some newer devices where we didn’t see a path to meaningful returns. In other cases, we looked at some programs that weren’t producing the returns we’d hoped (e.g. free shipping for all online grocery orders over $35) and amended them. We also reprioritized where to spend our resources, which ultimately led to the hard decision to eliminate 27,000 corporate roles. There are a number of other changes that we’ve made over the last several months to streamline our overall costs, and like most leadership teams, we’ll continue to evaluate what we’re seeing in our business and proceed adaptively.'), Document(page_content='We also looked hard at how we were working together as a team and asked our corporate employees to come back to the office at least three days a week, beginning in May. During the pandemic, our employees rallied to get work done from home and did everything possible to keep up with the unexpected circumstances that presented themselves. It was impressive and I’m proud of the way our collective team came together to overcome unprecedented challenges for our customers, communities, and business. But, we don’t think it’s the best long-term approach. We’ve become convinced that collaborating and inventing is easier and more effective when we’re working together and learning from one another in person. The energy and riffing on one another’s ideas happen more freely, and many of the best Amazon inventions have had their breakthrough moments from people staying behind after a meeting and working through ideas on a whiteboard, or continuing the conversation on the walk back from a meeting, or just popping by a teammate’s office later that day with another thought. Invention is often messy. It wanders and meanders and marinates. Serendipitous interactions help it, and there are more of those in-person than virtually. It’s also significantly easier to learn, model, practice, and strengthen our culture when we’re in the office together most of the time and surrounded by our colleagues. Innovation and our unique culture have been incredibly important in our first 29 years as a company, and I expect it will be comparably so in the next 29.\\n\\nA critical challenge we’ve continued to tackle is the rising cost to serve in our Stores fulfillment network (i.e. the cost to get a product from Amazon to a customer)—and we’ve made several changes that we believe will meaningfully improve our fulfillment costs and speed of delivery.\\n\\nDuring the early part of the pandemic, with many physical stores shut down, our consumer business grew at an extraordinary clip, with annual revenue increasing from $245B in 2019 to $434B in 2022. This meant that we had to double the fulfillment center footprint that we’d built over the prior 25 years and substantially accelerate building a last-mile transportation network that’s now the size of UPS (along with a new sortation center network to assist with efficiency and speed when items needed to traverse long distances)—all in the span of about two years. This was no easy feat, and hundreds of thousands of Amazonians worked very hard to make this happen. However, not surprisingly, with that rate and scale of change, there was a lot of optimization needed to yield the intended productivity. Over the last several months, we’ve scrutinized every process path in our fulfillment centers and transportation network and redesigned scores of processes and mechanisms, resulting in steady productivity gains and cost reductions over the last few quarters. There’s more work to do, but we’re pleased with our trajectory and the meaningful upside in front of us.'), Document(page_content='We also took this occasion to make larger structural changes that set us up better to deliver lower costs and faster speed for many years to come. A good example was reevaluating how our US fulfillment network was organized. Until recently, Amazon operated one national US fulfillment network that distributed inventory from fulfillment centers spread across the entire country. If a local fulfillment center didn’t have the product a customer ordered, we’d end up shipping it from other parts of the country, costing us more and increasing delivery times. This challenge became more pronounced as our fulfillment network expanded to hundreds of additional nodes over the last few years, distributing inventory across more locations and increasing the complexity of connecting the fulfillment center and delivery station nodes efficiently. Last year, we started rearchitecting our inventory placement strategy and leveraging our larger fulfillment center footprint to move from a national fulfillment network to a regionalized network model. We made significant internal changes (e.g. placement and logistics software, processes, physical operations) to create eight interconnected regions in smaller geographic areas. Each of these regions has broad, relevant selection to operate in a largely self-sufficient way, while still being able to ship nationally when necessary. Some of the most meaningful and hard work came from optimizing the connections between this large amount of infrastructure. We also continue to improve our advanced machine learning algorithms to better predict what customers in various parts of the country will need so that we have the right inventory in the right regions at the right time. We’ve recently completed this regional roll out and like the early results. Shorter travel distances mean lower cost to serve, less impact on the environment, and customers getting their orders faster. On the latter, we’re excited about seeing more next day and same-day deliveries, and we’re on track to have our fastest Prime delivery speeds ever in 2023. Overall, we remain confident about our plans to lower costs, reduce delivery times, and build a meaningfully larger retail business with healthy operating margins.\\n\\nAWS has an $85B annualized revenue run rate, is still early in its adoption curve, but at a juncture where it’s critical to stay focused on what matters most to customers over the long-haul. Despite growing 29% year-over-year (“YoY”) in 2022 on a $62B revenue base, AWS faces short-term headwinds right now as companies are being more cautious in spending given the challenging, current macroeconomic conditions. While some companies might obsess over how they could extract as much money from customers as possible in these tight times, it’s neither what customers want nor best for customers in the long term, so we’re taking a different tack. One of the many advantages of AWS and cloud computing is that when your business grows, you can seamlessly scale up; and conversely, if your business contracts, you can choose to give us back that capacity and cease paying for it. This elasticity is unique to the cloud, and doesn’t exist when you’ve already made expensive capital investments in your own on-premises datacenters, servers, and networking gear. In AWS, like all our businesses, we’re not trying to optimize for any one quarter or year. We’re trying to build customer relationships (and a business) that outlast all of us; and as a result, our AWS sales and support teams are spending much of their time helping customers optimize their AWS spend so they can better weather this uncertain economy. Many of these AWS customers tell us that they’re not cost-cutting as much as cost-optimizing so they can take their resources and apply them to emerging and inventive new customer experiences they’re planning. Customers have appreciated this customer-focused, long-term approach, and we think it’ll bode well for both customers and AWS.'), Document(page_content='While these short-term headwinds soften our growth rate, we like a lot of the fundamentals that we’re seeing in AWS. Our new customer pipeline is robust, as are our active migrations. Many companies use discontinuous periods like this to step back and determine what they strategically want to change, and we find an increasing number of enterprises opting out of managing their own infrastructure, and preferring to move to AWS to enjoy the agility, innovation, cost-efficiency, and security benefits. And most importantly for customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launched in 2022), and invest in long-term inventions that change what’s possible.\\n\\nChip development is a good example. In last year’s letter, I mentioned the investment we were making in our general-purpose CPU processors named Graviton. Graviton2-based compute instances deliver up to 40% better price-performance than the comparable latest generation x86-based instances; and in 2022, we delivered our Graviton3 chips, providing 25% better performance than the Graviton2 processors. Further, as machine learning adoption has continued to accelerate, customers have yearned for lower-cost GPUs (the chips most commonly used for machine learning). AWS started investing years ago in these specialized chips for machine learning training and inference (inferences are the predictions or answers that a machine learning model provides). We delivered our first training chip in 2022 (“Trainium”); and for the most common machine learning models, Trainium-based instances are up to 140% faster than GPU-based instances at up to 70% lower cost. Most companies are still in the training stage, but as they develop models that graduate to large-scale production, they’ll find that most of the cost is in inference because models are trained periodically whereas inferences are happening all the time as their associated application is being exercised. We launched our first inference chips (“Inferentia”) in 2019, and they have saved companies like Amazon over a hundred million dollars in capital expense already. Our Inferentia2 chip, which just launched, offers up to four times higher throughput and ten times lower latency than our first Inferentia processor. With the enormous upcoming growth in machine learning, customers will be able to get a lot more done with AWS’s training and inference chips at a significantly lower cost. We’re not close to being done innovating here, and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the early stages of its evolution, and has a chance for unusual growth in the next decade.\\n\\nSimilarly high potential, Amazon’s Advertising business is uniquely effective for brands, which is part of why it continues to grow at a brisk clip. Akin to physical retailers’ advertising businesses selling shelf space, end-caps, and placement in their circulars, our sponsored products and brands offerings have been an integral part of the Amazon shopping experience for more than a decade. However, unlike physical retailers, Amazon can tailor these sponsored products to be relevant to what customers are searching for given what we know about shopping behaviors and our very deep investment in machine learning algorithms. This leads to advertising that’s more useful for customers; and as a result, performs better for brands. This is part of why our Advertising revenue has continued to grow rapidly (23% YoY in Q4 2022, 25% YoY overall for 2022 on a $31B revenue base), even as most large advertising-focused businesses’ growth have slowed over the last several quarters.'), Document(page_content='We strive to be the best place for advertisers to build their brands. We have near and long-term opportunities that will help us achieve that mission. We’re continuing to make large investments in machine learning to keep honing our advertising selection algorithms. For the past couple of years, we’ve invested in building comprehensive, flexible, and durable planning and measurement solutions, giving marketers greater insight into advertising effectiveness. An example is Amazon Marketing Cloud (“AMC”). AMC is a “clean room” (i.e. secure digital environment) in which advertisers can run custom audience and campaign analytics across a range of first and third-party inputs, in a privacy-safe manner, to generate advertising and business insights to inform their broader marketing and sales strategies. The Advertising and AWS teams have collaborated to enable companies to store their data in AWS, operate securely in AMC with Amazon and other third-party data sources, perform analytics in AWS, and have the option to activate advertising on Amazon or third-party publishers through the Amazon Demand-Side Platform. Customers really like this concerted capability. We also see future opportunity to thoughtfully integrate advertising into our video, live sports, audio, and grocery products. We’ll continue to work hard to help brands uniquely engage with the right audience, and grow this part of our business.\\n\\nWhile it’s tempting in turbulent times only to focus on your existing large businesses, to build a sustainable, long-lasting, growing company that helps customers across a large number of dimensions, you can’t stop inventing and working on long-term customer experiences that can meaningfully impact customers and your company.\\n\\nWhen we look at new investment opportunities, we ask ourselves a few questions:\\n\\nIf we were successful, could it be big and have a reasonable return on invested capital?\\nIs the opportunity being well-served today?\\nDo we have a differentiated approach?\\nAnd, do we have competence in that area? And if not, can we acquire it quickly?\\nIf we like the answers to those questions, then we’ll invest. This process has led to some expansions that seem straightforward, and others that some folks might not have initially guessed.\\n\\nThe earliest example is when we chose to expand from just selling Books, to adding categories like Music, Video, Electronics, and Toys. Back then (1998-1999), it wasn’t universally applauded, but in retrospect, it seems fairly obvious.\\n\\nThe same could be said for our international Stores expansion. In 2022, our international consumer segment drove $118B of revenue. In our larger, established international consumer businesses, we’re big enough to be impacted by the slowing macroeconomic conditions; however, the growth in 2019-2021 on a large base was remarkable—30% compound annual growth rate (“CAGR”) in the UK, 26% in Germany, and 21% in Japan (excluding the impact of FX). Over the past several years, we’ve invested in new international geographies, including India, Brazil, Mexico, Australia, various European countries, the Middle East, and parts of Africa. These new countries take a certain amount of fixed investment to get started and to scale, but we like the trajectory they’re on, and their growth patterns resemble what we’ve seen in North America and our established international geographies. Emerging countries sometimes lack some of the infrastructure and services that our business relies on (e.g. payment methods, transportation services, and internet/telecom infrastructure). To solve these challenges, we continue to work with various partners to deliver solutions for customers. Ultimately, we believe that this investment in serving a broader geographical footprint will allow us to help more customers across the world, as well as build a larger free cash flow-generating consumer business.'), Document(page_content='Beyond geographic expansion, we’ve been working to expand our customer offerings across some large, unique product retail market segments. Grocery is an $800B market segment in the US alone, with the average household shopping three to four times per week. Amazon has built a somewhat unusual, but significant grocery business over nearly 20 years. Similar to how other mass merchants entered the grocery space in the 1980s, we began by adding products typically found in supermarket aisles that don’t require temperature control such as paper products, canned and boxed food, candy and snacks, pet care, health and personal care, and beauty. However, we offer more than three million items compared to a typical supermarket’s 30K for the same categories. To date, we’ve also focused on larger pack sizes, given the current cost to serve online delivery. While we’re pleased with the size and growth of our grocery business, we aspire to serve more of our customers’ grocery needs than we do today. To do so, we need a broader physical store footprint given that most of the grocery shopping still happens in physical venues. Whole Foods Market pioneered the natural and organic specialty grocery store concept 40 years ago. Today, it’s a large and growing business that continues to raise the bar for healthy and sustainable food. Over the past year, we’ve continued to invest in the business while also making changes to drive better profitability. Whole Foods is on an encouraging path, but to have a larger impact on physical grocery, we must find a mass grocery format that we believe is worth expanding broadly. Amazon Fresh is the brand we’ve been experimenting with for a few years, and we’re working hard to identify and build the right mass grocery format for Amazon scale. Grocery is a big growth opportunity for Amazon.\\n\\nAmazon Business is another example of an investment where our ecommerce and logistics capabilities position us well to pursue this large market segment. Amazon Business allows businesses, municipalities, and organizations to procure products like office supplies and other bulk items easily and at great savings. While some areas of the economy have struggled over the past few years, Amazon Business has thrived. Why? Because the team has translated what it means to deliver selection, value, and convenience into a business procurement setting, constantly listening to and learning from customers, and innovating on their behalf. Some people have never heard of Amazon Business, but, our business customers love it. Amazon Business launched in 2015 and today drives roughly $35B in annualized gross sales. More than six million active customers, including 96 of the global Fortune 100 companies, are enjoying Amazon Business’ one-stop shopping, real-time analytics, and broad selection on hundreds of millions of business supplies. We believe that we’ve only scratched the surface of what’s possible to date, and plan to keep building the features our business customers tell us they need and want.'), Document(page_content='While many brands and merchants successfully sell their products on Amazon’s marketplace, there are also a large number of brands and sellers who have launched their own direct-to-consumer websites. One of the challenges for these merchants is driving conversion from views to purchases. We invented Buy with Prime to help with this challenge. Buy with Prime allows third-party brands and sellers to offer their products on their own websites to our large Amazon Prime membership, and offer those customers fast, free Prime shipping and seamless checkout with their Amazon account. Buy with Prime provides merchants several additional benefits, including Amazon handling the product storage, picking, packing, delivery, payment, and any returns, all through Amazon Pay and Fulfillment by Amazon. Buy with Prime has recently been made available to all US merchants; and so far, Buy with Prime has increased shopper conversion on third-party shopping sites by 25% on average. Merchants are excited about converting more sales and fulfilling these shipments more easily, Prime members love that they can use their Prime benefits on more destinations, and Buy with Prime allows us to improve the shopping experience across more of the web.\\n\\nExpanding internationally, pursuing large retail market segments that are still nascent for Amazon, and using our unique assets to help merchants sell more effectively on their own websites are somewhat natural extensions for us. There are also a few investments we’re making that are further from our core businesses, but where we see unique opportunity. In 2003, AWS would have been a classic example. In 2023, Amazon Healthcare and Kuiper are potential analogues.\\n\\nOur initial efforts in Healthcare began with pharmacy, which felt less like a major departure from ecommerce. For years, Amazon customers had asked us when we’d offer them an online pharmacy as their frustrations mounted with current providers. Launched in 2020, Amazon Pharmacy is a full-service, online pharmacy that offers transparent pricing, easy refills, and savings for Prime members. The business is growing quickly, and continues to innovate. An example is Amazon Pharmacy’s recent launch of RxPass, which for a $5 per month flat fee, enables Prime members to get as many of the eligible prescription medications as they need for dozens of common conditions, like high blood pressure, acid reflux, and anxiety. However, our customers have continued to express a strong desire for Amazon to provide a better alternative to the inefficient and unsatisfying broader healthcare experience. We decided to start with primary care as it’s a prevalent first stop in the patient journey. We evaluated and studied the existing landscape extensively, including some early Amazon experiments like Amazon Care. During this process, we identified One Medical’s patient-focused experience as an excellent foundation upon which to build our future business; and in July 2022, we announced our acquisition of One Medical. There are several elements that customers love about One Medical. It has a fantastic digital app that makes it easy for patients to discuss issues with a medical practitioner via chat or video conference. If a physical visit is required, One Medical has offices in cities across the US where patients can book same or next day appointments. One Medical has relationships with specialty physicians in each of its cities and works closely with local hospital systems to make seeing specialists easy, so One Medical members can quickly access these resources when needed. Going forward, we strongly believe that One Medical and Amazon will continue to innovate together to change what primary care will look like for customers.'), Document(page_content='Kuiper is another example of Amazon innovating for customers over the long term in an area where there’s high customer need. Our vision for Kuiper is to create a low-Earth orbit satellite system to deliver high-quality broadband internet service to places around the world that don’t currently have it. There are hundreds of millions of households and businesses who don’t have reliable access to the internet. Imagine what they’ll be able to do with reliable connectivity, from people taking online education courses, using financial services, starting their own businesses, doing their shopping, enjoying entertainment, to businesses and governments improving their coverage, efficiency, and operations. Kuiper will deliver not only accessibility, but affordability. Our teams have developed low-cost antennas (i.e. customer terminals) that will lower the barriers to access. We recently unveiled the new terminals that will communicate with the satellites passing overhead, and we expect to be able to produce our standard residential version for less than $400 each. They’re small: 11 inches square, 1 inch thick, and weigh less than 5 pounds without their mounting bracket, but they deliver speeds up to 400 megabits per second. And they’re powered by Amazon-designed baseband chips. We’re preparing to launch two prototype satellites to test the entire end-to-end communications network this year, and plan to be in beta with commercial customers in 2024. The customer reaction to what we’ve shared thus far about Kuiper has been very positive, and we believe Kuiper represents a very large potential opportunity for Amazon. It also shares several similarities to AWS in that it’s capital intensive at the start, but has a large prospective consumer, enterprise, and government customer base, significant revenue and operating profit potential, and relatively few companies with the technical and inventive aptitude, as well as the investment hypothesis to go after it.'), Document(page_content='One final investment area that I’ll mention, that’s core to setting Amazon up to invent in every area of our business for many decades to come, and where we’re investing heavily is Large Language Models (“LLMs”) and Generative AI. Machine learning has been a technology with high promise for several decades, but it’s only been the last five to ten years that it’s started to be used more pervasively by companies. This shift was driven by several factors, including access to higher volumes of compute capacity at lower prices than was ever available. Amazon has been using machine learning extensively for 25 years, employing it in everything from personalized ecommerce recommendations, to fulfillment center pick paths, to drones for Prime Air, to Alexa, to the many machine learning services AWS offers (where AWS has the broadest machine learning functionality and customer base of any cloud provider). More recently, a newer form of machine learning, called Generative AI, has burst onto the scene and promises to significantly accelerate machine learning adoption. Generative AI is based on very Large Language Models (trained on up to hundreds of billions of parameters, and growing), across expansive datasets, and has radically general and broad recall and learning capabilities. We have been working on our own LLMs for a while now, believe it will transform and improve virtually every customer experience, and will continue to invest substantially in these models across all of our consumer, seller, brand, and creator experiences. Additionally, as we’ve done for years in AWS, we’re democratizing this technology so companies of all sizes can leverage Generative AI. AWS is offering the most price-performant machine learning chips in Trainium and Inferentia so small and large companies can afford to train and run their LLMs in production. We enable companies to choose from various LLMs and build applications with all of the AWS security, privacy and other features that customers are accustomed to using. And, we’re delivering applications like AWS’s CodeWhisperer, which revolutionizes developer productivity by generating code suggestions in real time. I could write an entire letter on LLMs and Generative AI as I think they will be that transformative, but I’ll leave that for a future letter. Let’s just say that LLMs and Generative AI are going to be a big deal for customers, our shareholders, and Amazon.\\n \\nSo, in closing, I’m optimistic that we’ll emerge from this challenging macroeconomic time in a stronger position than when we entered it. There are several reasons for it and I’ve mentioned many of them above. But, there are two relatively simple statistics that underline our immense future opportunity. While we have a consumer business that’s $434B in 2022, the vast majority of total market segment share in global retail still resides in physical stores (roughly 80%). And, it’s a similar story for Global IT spending, where we have AWS revenue of $80B in 2022, with about 90% of Global IT spending still on-premises and yet to migrate to the cloud. As these equations steadily flip—as we’re already seeing happen—we believe our leading customer experiences, relentless invention, customer focus, and hard work will result in significant growth in the coming years. And, of course, this doesn’t include the other businesses and experiences we’re pursuing at Amazon, all of which are still in their early days.\\n\\nI strongly believe that our best days are in front of us, and I look forward to working with my teammates at Amazon to make it so.')], 'output_text': '\\nJeff Bezos, the CEO of Amazon, remains positive and energized about the company\\'s future despite facing challenges in 2022. The company grew demand, innovated in its largest businesses, and made adjustments to its investment decisions while preserving long-term investments. Amazon\\'s success can be attributed to its ability to adapt to changing market conditions and customer needs.\\n\\nIn 2001, Amazon faced a dot-com crash and had to secure letters of credit to buy inventory, streamline costs, and prioritize the long-term customer experience. In 2008-2009, they took several actions to manage the cost structure and efficiency of their Stores business while balancing this streamlining with investment in customer experiences. AWS is now an $85B annual revenue run rate business with strong profitability, having transformed how customers from start-ups to multinational companies to public sector organizations manage their technology infrastructure.\\n\\nAmazon has taken a deep look across the company, business by business, invention by invention, and asked themselves whether they had conviction about each initiative\\'s long-term potential to drive enough revenue, operating income, free cash flow, and return on invested capital. This has led to the closure of certain businesses, such as Bookstores and 4 Star stores, the closure of Amazon Fabric and Amazon Care efforts, and the elimination of 27,000 corporate roles. They have also reprioritized where to spend their resources, leading to the hard decision to eliminate 27,000 corporate roles.\\n\\nAmazon has decided to require its corporate employees to return to the office at least three days a week, starting in May. The company believes that collaborating and inventing is easier and more effective when done in person, and many of its best inventions have come from serendipitous interactions in the office. The rising cost to serve in its Stores fulfillment network has been a critical challenge, and the company has made several changes to improve fulfillment costs and speed of delivery. During the early part of the pandemic, Amazon\\'s consumer business grew at an extraordinary clip, doubling the fulfillment center footprint and substantially accelerating building a last-mile transportation network.\\n\\nAmazon has made significant structural changes to deliver lower costs and faster speed for many years to come. These changes include reevaluating how its US fulfillment network was organized and leveraging its larger fulfillment center footprint to move from a national fulfillment network to a regionalized network model. AWS has improved its advanced machine learning algorithms to better predict what customers in various parts of the country will need, allowing for more next-day and same-day deliveries. The company remains confident about its plans to lower costs, reduce delivery times, and build a meaningfully larger retail business with healthy operating margins. AWS has an $85B annualized revenue run rate and is still early in its adoption curve, but it is important to stay focused on what matters most to customers over the long term.\\n\\nDespite growing 29% year-over-year in 2022, AWS faces short-term headwinds as companies are being more cautious in spending due to the challenging macroeconomic conditions. AWS is taking a different tack, focusing on building customer relationships and a business that outlasts all of us. This approach has been appreciated by customers, who are not cost-cutting as much as cost-optimizing to apply their resources to emerging and inventive new customer experiences. AWS faces short-term challenges, but it remains strong due to a robust customer pipeline, active migrations, and enterprises opting for AWS for its agility, innovation, cost-efficiency, and security benefits. The company continues to deliver new capabilities rapidly and invests in long-term inventions, such as its Graviton CPU processors and GPU chips for machine learning training and inference.\\n\\nAmazon\\'s Advertising business is also growing rapidly, benefiting from its ability to tailor sponsored products to customer search queries and its deep investment in machine learning algorithms. This leads to more useful and effective advertising for brands, which performs better for them. Amazon Advertising is committed to being the best place for advertisers to build their brands. They are investing in machine learning to improve their advertising selection algorithms and building comprehensive, flexible, and durable planning and measurement solutions. Amazon Marketing Cloud (AMC) is a \"clean room\" where advertisers can run custom audience and campaign analytics in a privacy-safe manner.\\n\\nThe Advertising and AWS teams have collaborated to enable companies to store their data in AWS, operate securely in AMC, perform analytics in AWS, and activate advertising on Amazon or third-party publishers through the Amazon Demand-Side Platform. Amazon is also looking at new investment opportunities, such as expanding from just selling Books to adding categories like Music, Video, Electronics, and Toys. They have also expanded their international Stores, with $118B of revenue in 2022. To solve these challenges, they are working with partners to deliver solutions for customers. Ultimately, this investment in serving a broader geographical footprint will allow them to help more customers across the world and build a larger free cash flow-generating consumer business.\\n\\nAmazon has been expanding its customer offerings across large, unique product retail market segments, such as grocery. It has built a significant grocery business over nearly 20 years, offering more than three million items compared to a typical supermarket\\'s 30K. To serve more of its customers\\' grocery needs, Amazon needs a broader physical store footprint. Whole Foods Market pioneered the natural and organic specialty grocery store concept 40 years ago, and Amazon Fresh is the brand they\\'ve been experimenting with for a few years. Amazon Business is another example of an investment where their ecommerce and logistics capabilities position them well to pursue this large market segment. It launched in 2015 and drives roughly $35B in annualized gross sales, with more than six million active customers, including 96 of the global Fortune 100 companies.\\n\\nAmazon has developed Buy with Prime to assist third-party brands and sellers in offering their products on their websites to Amazon Prime members. It provides merchants with additional benefits such as Amazon handling product storage, picking, packing, delivery, payment, and returns. It has increased shopper conversion on third-party shopping sites by 25% on average. Amazon is expanding internationally, pursuing large retail market segments, and using its unique assets to help merchants sell more effectively on their websites. In 2003, AWS was a classic example; in 2023, Amazon Healthcare and Kuiper are potential analogues.\\n\\nAmazon Pharmacy is a full-service, online pharmacy that offers transparent pricing, easy refills, and savings for Prime members. However, customers have expressed a strong desire for Amazon to provide a better alternative to the inefficient and unsatisfying broader healthcare experience. In July 2022, Amazon announced its acquisition of One Medical, a patient-focused experience with a digital app and offices in cities across the US. One Medical has relationships with specialty physicians and works closely with local hospital systems to make seeing specialists easy. Amazon and One Medical will continue to innovate together to change primary care.\\n\\nAmazon is creating Kuiper, a low-Earth orbit satellite system to deliver high-quality broadband internet service to places around the world that don\\'t currently have it. The system will deliver not only accessibility but affordability, with low-cost antennas that will lower the barriers to access. The company is preparing to launch two prototype satellites to test the entire end-to-end communications network this year and plans to be in beta with commercial customers in 2024. Kuiper represents a large potential opportunity for Amazon, with a large prospective consumer, enterprise, and government customer base, significant revenue and operating profit potential, and relatively few companies with the technical and inventive aptitude to go after it.\\n\\nAmazon is investing heavily in Large Language Models (LLMs) and Generative AI, which have the potential to transform and improve customer experiences across all of its consumer, seller, brand, and creator experiences. Machine learning has been a technology with high promise for several decades, but it has only been the last five to ten years that it has started to be used more pervasively by companies. Generative AI is based on very Large Language Models (trained on up to hundreds of billions of parameters, and growing), across expansive datasets, and has radically general and broad recall and learning capabilities. AWS is offering the most price-performant machine learning chips in Trainium and Inferentia, so small and large companies can afford to train and run their LLMs in production.\\n\\nLLMs and Generative AI are going to be a big deal for customers, our shareholders, and Amazon, and AWS is democratizing this technology so companies of all sizes can leverage it. The most important details in this text are the two relatively simple statistics that underline Amazon\\'s immense future opportunity. While Amazon has a consumer business that\\'s $434B in 2022, the vast majority of total market segment share in global retail still resides in physical stores (roughly 80%). And, while AWS has revenue of $80B in 2022, with about 90% of Global IT spending still on-premises and yet to migrate to the cloud, these equations are steadily flipping, and Amazon believes its leading customer experiences, relentless invention, customer focus, and hard work will result in significant growth in the coming years.\\n\\nAmazon is optimistic that it will emerge from this challenging macroeconomic time in a stronger position than when it entered it, and believes its best days are in front of it. It is pursuing other businesses and experiences, all of which are still in their early days.'}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
