{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos do Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de modelos disponíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon.titan-tg1-large\n",
      "amazon.titan-image-generator-v1:0\n",
      "amazon.titan-image-generator-v1\n",
      "amazon.titan-embed-g1-text-02\n",
      "amazon.titan-text-lite-v1:0:4k\n",
      "amazon.titan-text-lite-v1\n",
      "amazon.titan-text-express-v1:0:8k\n",
      "amazon.titan-text-express-v1\n",
      "amazon.titan-embed-text-v1:2:8k\n",
      "amazon.titan-embed-text-v1\n",
      "amazon.titan-embed-text-v2:0:8k\n",
      "amazon.titan-embed-text-v2:0\n",
      "amazon.titan-embed-image-v1:0\n",
      "amazon.titan-embed-image-v1\n",
      "stability.stable-diffusion-xl-v1:0\n",
      "stability.stable-diffusion-xl-v1\n",
      "ai21.j2-grande-instruct\n",
      "ai21.j2-jumbo-instruct\n",
      "ai21.j2-mid\n",
      "ai21.j2-mid-v1\n",
      "ai21.j2-ultra\n",
      "ai21.j2-ultra-v1:0:8k\n",
      "ai21.j2-ultra-v1\n",
      "anthropic.claude-instant-v1:2:100k\n",
      "anthropic.claude-instant-v1\n",
      "anthropic.claude-v2:0:18k\n",
      "anthropic.claude-v2:0:100k\n",
      "anthropic.claude-v2:1:18k\n",
      "anthropic.claude-v2:1:200k\n",
      "anthropic.claude-v2:1\n",
      "anthropic.claude-v2\n",
      "anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "anthropic.claude-3-sonnet-20240229-v1:0\n",
      "anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "anthropic.claude-3-haiku-20240307-v1:0\n",
      "cohere.command-text-v14:7:4k\n",
      "cohere.command-text-v14\n",
      "cohere.command-r-v1:0\n",
      "cohere.command-r-plus-v1:0\n",
      "cohere.command-light-text-v14:7:4k\n",
      "cohere.command-light-text-v14\n",
      "cohere.embed-english-v3:0:512\n",
      "cohere.embed-english-v3\n",
      "cohere.embed-multilingual-v3:0:512\n",
      "cohere.embed-multilingual-v3\n",
      "meta.llama2-13b-chat-v1:0:4k\n",
      "meta.llama2-13b-chat-v1\n",
      "meta.llama2-70b-chat-v1:0:4k\n",
      "meta.llama2-70b-chat-v1\n",
      "meta.llama2-13b-v1:0:4k\n",
      "meta.llama2-13b-v1\n",
      "meta.llama2-70b-v1:0:4k\n",
      "meta.llama2-70b-v1\n",
      "meta.llama3-8b-instruct-v1:0\n",
      "meta.llama3-70b-instruct-v1:0\n",
      "mistral.mistral-7b-instruct-v0:2\n",
      "mistral.mixtral-8x7b-instruct-v0:1\n",
      "mistral.mistral-large-2402-v1:0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "bedrock = boto3.client(service_name='bedrock')\n",
    "model_list=bedrock.list_foundation_models()\n",
    "for x in range(len(model_list.get('modelSummaries'))):\n",
    "     print(model_list.get('modelSummaries')[x]['modelId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InvokeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amazon Bedrock is a managed service that makes foundation models from leading AI startup and Amazon's own Titan models available through APIs. For up-to-date information on Amazon Bedrock and how 3P models are approved, endorsed or selected please see the provided documentation and relevant FAQs.\n"
     ]
    }
   ],
   "source": [
    "bedrock_rt = boto3.client(service_name='bedrock-runtime')\n",
    "prompt = \"What is Amazon Bedrock?\"\n",
    "configs= {\n",
    "\"inputText\": prompt,\n",
    "\"textGenerationConfig\": {\n",
    "\"maxTokenCount\": 4096,\n",
    "\"stopSequences\": [],\n",
    "\"temperature\":0,\n",
    "\"topP\":1\n",
    "}\n",
    "}\n",
    "body=json.dumps(configs)\n",
    "modelId = 'amazon.titan-tg1-large'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "response = bedrock_rt.invoke_model(\n",
    "     body=body,\n",
    "     modelId=modelId,\n",
    "     accept=accept,\n",
    "     contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get('body').read())\n",
    "print(response_body.get('results')[0].get('outputText'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InvokeModelWithResponseStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputText': '\\nLiving on Mars would be a challenging and exciting adventure. It would require a significant investment in technology and infrastructure to create a sustainable environment, including a habitat, food production, and energy systems.\\n\\nMartian gravity is weaker tha', 'index': 0, 'totalOutputTextTokenCount': None, 'completionReason': None, 'inputTextTokenCount': 13}\n",
      "{'outputText': \"n Earth's, which would require adaptations to prevent injury and maintain muscle mass. Additionally, Martian weather can be extreme, with high temperatures, dust storms, and polar ice caps.\\n\\nLiving on Mars would also require a significant amount of self-sufficiency and resilience, as individuals would be isolated from their families and friends and would face the challenges of living in a new and unfamiliar environment. However,\", 'index': 0, 'totalOutputTextTokenCount': 129, 'completionReason': 'LENGTH', 'inputTextTokenCount': None, 'amazon-bedrock-invocationMetrics': {'inputTokenCount': 13, 'outputTokenCount': 129, 'invocationLatency': 3616, 'firstByteLatency': 2211}}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write an essay for living on Mars using 10 sentences.\"\n",
    "\n",
    "configs= {\n",
    "     \"inputText\": prompt,\n",
    "     \"textGenerationConfig\": {\n",
    "          \"temperature\":0\n",
    "     }\n",
    "}\n",
    "\n",
    "body=json.dumps(configs)\n",
    "\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "modelId = 'amazon.titan-tg1-large'\n",
    "\n",
    "response = bedrock_rt.invoke_model_with_response_stream(\n",
    "     modelId=modelId,\n",
    "     body=body,\n",
    "     accept=accept,\n",
    "     contentType=contentType\n",
    ")\n",
    "\n",
    "stream = response.get('body')\n",
    "if stream:\n",
    "     for event in stream:\n",
    "          chunk = event.get('chunk')\n",
    "          if chunk:\n",
    "               print((json.loads(chunk.get('bytes').decode())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
